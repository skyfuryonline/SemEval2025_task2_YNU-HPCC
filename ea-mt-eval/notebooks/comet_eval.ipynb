{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# COMET evaluation for the Entity-Aware Machine Translation (EA-MT) task\n",
    "This notebook provides an example of how to evaluate the Entity-Aware Machine Translation (EA-MT) task using the COMET evaluation metric. The EA-MT task is a variant of the machine translation task where the source text contains named entities that need to be translated correctly.\n",
    "\n",
    "**NOTE**: The COMET evaluation metric computes the accuracy/quality of the translation at the sentence level, i.e., it may not correlate well with the quality of the translation of the named entities. For an evaluation metric that is more sensitive to the quality of the translation of named entities, please take a look at our notebook on our manual Entity-level Translation Accuracy (m-ETA) metric."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Setup\n",
    "First, we need to install the `comet` library, which we will use to download the pre-trained models and evaluate the translations.\n",
    "\n",
    "### Installation with virtual environment\n",
    "We recommend using a virtual environment to install the `unbabel-comet` library. This is usually not necessary if you are using a platform like Colab, which already provides a virtual environment.\n",
    "\n",
    "You can create a virtual environment using `venv` or `conda`. Here, we will use `conda` to create a virtual environment and install the `unbabel-comet` library.\n",
    "\n",
    "```bash\n",
    "# Create a virtual environment\n",
    "conda create -n comet python=3.10\n",
    "\n",
    "# Always activate the virtual environment before installing the library\n",
    "conda activate comet\n",
    "\n",
    "# Install the comet library\n",
    "pip install unbabel-comet\n",
    "```\n",
    "\n",
    "### Installation without virtual environment\n",
    "If you are not using a virtual environment, you can install the `unbabel-comet` library using the following command:\n",
    "\n",
    "```bash\n",
    "pip install unbabel-comet\n",
    "```\n",
    "\n",
    "## Data\n",
    "This notebook expects the data to be organized in the following way:\n",
    "```shell\n",
    "data\n",
    "├── predictions\n",
    "│   └── <your_model_name>\n",
    "│       └── validation\n",
    "│           ├── ar_AE.jsonl\n",
    "│           ├── de_DE.jsonl\n",
    "│           ├── es_ES.jsonl\n",
    "│           ├── fr_FR.jsonl\n",
    "│           ├── it_IT.jsonl\n",
    "│           ├── ja_JP.jsonl\n",
    "│           ├── ko_KR.jsonl\n",
    "│           ├── th_TH.jsonl\n",
    "│           ├── tr_TR.jsonl\n",
    "│           └── zh_TW.jsonl\n",
    "└── references\n",
    "    ├── sample\n",
    "    │   ├── ar_AE.jsonl\n",
    "    │   ├── de_DE.jsonl\n",
    "    │   ├── es_ES.jsonl\n",
    "    │   ├── fr_FR.jsonl\n",
    "    │   ├── it_IT.jsonl\n",
    "    │   ├── ja_JP.jsonl\n",
    "    │   ├── ko_KR.jsonl\n",
    "    │   ├── th_TH.jsonl\n",
    "    │   ├── tr_TR.jsonl\n",
    "    │   └── zh_TW.jsonl\n",
    "    ├── test\n",
    "    │   ├── ar_AE.jsonl\n",
    "    │   ├── de_DE.jsonl\n",
    "    │   ├── es_ES.jsonl\n",
    "    │   ├── fr_FR.jsonl\n",
    "    │   ├── it_IT.jsonl\n",
    "    │   ├── ja_JP.jsonl\n",
    "    │   ├── ko_KR.jsonl\n",
    "    │   ├── th_TH.jsonl\n",
    "    │   ├── tr_TR.jsonl\n",
    "    │   └── zh_TW.jsonl\n",
    "    └── validation\n",
    "        ├── ar_AE.jsonl\n",
    "        ├── de_DE.jsonl\n",
    "        ├── es_ES.jsonl\n",
    "        ├── fr_FR.jsonl\n",
    "        ├── it_IT.jsonl\n",
    "        ├── ja_JP.jsonl\n",
    "        ├── ko_KR.jsonl\n",
    "        ├── th_TH.jsonl\n",
    "        ├── tr_TR.jsonl\n",
    "        └── zh_TW.jsonl\n",
    "```\n",
    "\n",
    "### Data format for the predictions\n",
    "The data should be stored in JSONL format. Each line in the JSONL file should be a JSON object with the following keys:\n",
    "- `id`: a unique identifier for the translation that corresponds to the `id` in the reference file.\n",
    "- `source_language`: the source language of the translation.\n",
    "- `target_language`: the target language of the translation.\n",
    "- `text`: the original text in the source language.\n",
    "- `prediction`: the translated text in the target language.\n",
    "\n",
    "For example:\n",
    "```json\n",
    "{\"id\": \"1\", \"source_language\": \"English\", \"target_language\": \"German\", \"text\": \"Hello, how are you?\", \"prediction\": \"Hallo, wie geht es dir?\"}\n",
    "{\"id\": \"2\", \"source_language\": \"English\", \"target_language\": \"German\", \"text\": \"I am fine, thank you.\", \"prediction\": \"Mir geht es gut, danke.\"}\n",
    "```\n",
    "\n",
    "### Note\n",
    "Remember to change the following variables to match your data:\n",
    "- `PATH_TO_DATA_DIR`: the path to the directory containing the predictions and references.\n",
    "- `SYSTEM_NAME`: the name of your model.\n",
    "- `SPLIT`: the split of the data (e.g., `validation`, `test`).\n",
    "- `TARGET_LANGUAGE`: the target language of the translations; one of `ar_AE`, `de_DE`, `es_ES`, `fr_FR`, `it_IT`, `ja_JP`, `ko_KR`, `th_TH`, `tr_TR`, `zh_TW`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Import the comet module for the evaluation\n",
    "from comet import download_model, load_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMET_MODEL_NAME = \"Unbabel/wmt22-comet-da\"\n",
    "SYSTEM_NAME = \"DeepSeek(zh&tr&it)_validation\"\n",
    "SOURCE_LANGUAGE = \"en_US\"\n",
    "TARGET_LANGUAGE = \"it_IT\"# tr_TR zh_TW\n",
    "DATA_DIR = \"../data\"\n",
    "SPLIT = \"validation\"\n",
    "NUM_GPUS = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# The path to the references is formatted as follows:\n",
    "# data/references/{split}/{target_language}.jsonl\n",
    "PATH_TO_REFERENCES = os.path.join(\n",
    "    DATA_DIR,\n",
    "    \"references\",\n",
    "    SPLIT,\n",
    "    f\"{TARGET_LANGUAGE}.jsonl\",\n",
    ")\n",
    "\n",
    "# The path to the predictions is formatted as follows:\n",
    "# data/predictions/{system_name}/{split}/{target_language}.jsonl\n",
    "PATH_TO_PREDICTIONS = os.path.join(\n",
    "    DATA_DIR,\n",
    "    \"predictions\",\n",
    "    SYSTEM_NAME,\n",
    "    SPLIT,\n",
    "    f\"{TARGET_LANGUAGE}.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "Let's load the data that will be used for the evaluation.\n",
    "\n",
    "## Data overview\n",
    "Let's have a look at the data. The data is organized in JSONL format, where each line is a JSON object that contains the following fields (formatted for better readability):\n",
    "```json\n",
    "{\n",
    "  \"id\": \"Q1093267_0\",\n",
    "  \"wikidata_id\": \"Q1093267\",\n",
    "  \"entity_types\": [\n",
    "    \"TV series\"\n",
    "  ],\n",
    "  \"source\": \"How many episodes are in the TV series Space Battleship Yamato II?\",\n",
    "  \"targets\": [\n",
    "    {\n",
    "      \"translation\": \"Quanti episodi ci sono nella serie TV La corazzata Yamato?\",\n",
    "      \"mention\": \"La corazzata Yamato\"\n",
    "    },\n",
    "    {\n",
    "      \"translation\": \"Quanti episodi ci sono nella serie TV la corazzata Yamato?\",\n",
    "      \"mention\": \"la corazzata Yamato\"\n",
    "    }\n",
    "  ],\n",
    "  \"source_locale\": \"en\",\n",
    "  \"target_locale\": \"it\"\n",
    "}\n",
    "```\n",
    "\n",
    "## Things to note for data loading\n",
    "Since COMET does not support multi-reference translations, we will:\n",
    "1. Create an entry for each reference translation while keeping a reference to the source (e.g., `Q1093267_0`).\n",
    "2. Duplicate the predictions for each reference translation.\n",
    "3. Compute the COMET score for each prediction-reference pair.\n",
    "4. Get the maximum COMET score for each source-reference pair with the same source.\n",
    "5. Compute the average of the maximum COMET scores for each source-reference pair.\n",
    "\n",
    "In other words, we will compute the COMET score for each prediction-reference pair and then average the maximum scores for each source-reference pair with the same source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 730 references from ../data\\references\\validation\\it_IT.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Load the references\n",
    "references = {}\n",
    "\n",
    "with open(PATH_TO_REFERENCES, \"r\",encoding=\"utf-8\") as f:\n",
    "\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        references[data[\"id\"]] = data\n",
    "\n",
    "print(f\"Loaded {len(references)} references from {PATH_TO_REFERENCES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 730 predictions from ../data\\predictions\\DeepSeek(zh&tr&it)_validation\\validation\\it_IT.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Load the predictions\n",
    "predictions = {}\n",
    "\n",
    "with open(PATH_TO_PREDICTIONS, \"r\",encoding=\"utf-8\") as f:\n",
    "\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        predictions[data[\"id\"]] = data\n",
    "\n",
    "print(f\"Loaded {len(predictions)} predictions from {PATH_TO_PREDICTIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All references have a corresponding prediction\n"
     ]
    }
   ],
   "source": [
    "# Get all those references that have a corresponding prediction\n",
    "ids = set(references.keys()) & set(predictions.keys())\n",
    "num_missing_predictions = len(references) - len(ids)\n",
    "\n",
    "if num_missing_predictions > 0:\n",
    "    print(f\"Missing predictions for {num_missing_predictions} references\")\n",
    "else:\n",
    "    print(\"All references have a corresponding prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1268 instances\n"
     ]
    }
   ],
   "source": [
    "instance_ids = {}\n",
    "instances = []\n",
    "current_index = 0\n",
    "\n",
    "for id in sorted(list(ids)):\n",
    "    reference = references[id]\n",
    "    prediction = predictions[id]\n",
    "\n",
    "    for target in reference[\"targets\"]:\n",
    "        instances.append(\n",
    "            {\n",
    "                \"src\": reference[\"source\"],\n",
    "                \"ref\": target[\"translation\"],\n",
    "                \"mt\": prediction[\"prediction\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    instance_ids[id] = [current_index, current_index + len(reference[\"targets\"])]\n",
    "    current_index += len(reference[\"targets\"])\n",
    "\n",
    "print(f\"Created {len(instances)} instances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the COMET evaluation model\n",
    "Let's download the model and load it into the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\skyfu\\.cache\\huggingface\\hub\\models--Unbabel--wmt22-comet-da\\snapshots\\f49d328952c3470eff6bb6f545d62bfdb6e66304\\checkpoints\\model.ckpt`\n",
      "Encoder model frozen.\n",
      "D:\\anaconda\\Lib\\site-packages\\pytorch_lightning\\core\\saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "# Download the model\n",
    "model_path = download_model(COMET_MODEL_NAME)\n",
    "# Load the model\n",
    "model = load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the predictions\n",
    "We can now evaluate the predictions using the COMET evaluation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████████| 40/40 [01:48<00:00,  2.70s/it]\n"
     ]
    }
   ],
   "source": [
    "# Compute the scores\n",
    "outputs = model.predict(instances, batch_size=BATCH_SIZE, gpus=NUM_GPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average COMET score: 87.38\n"
     ]
    }
   ],
   "source": [
    "# Extract the scores\n",
    "scores = outputs.scores\n",
    "max_scores = []\n",
    "\n",
    "for id, indices in instance_ids.items():\n",
    "    # Get the max score for each reference\n",
    "    max_score = max(scores[indices[0] : indices[1]])\n",
    "    max_scores.append(max_score)\n",
    "\n",
    "# Compute the average score while taking into account the missing predictions (which are considered as 0)\n",
    "# system_score = sum(max_scores) / (len(max_scores) + num_missing_predictions)\n",
    "system_score = sum(max_scores) / (len(max_scores))\n",
    "print(f\"Average COMET score: {100.*system_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8607031721445476"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.system_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
