{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation with OpenAI's API\n",
    "This notebook demonstrates how to use OpenAI's API to translate text from one language to another. The API can be used to translate text between any pair of languages supported by the model. In this notebook, we will use the API to translate text from English to another language.\n",
    "\n",
    "## References\n",
    "- [OpenAI API](https://openai.com/index/openai-api/)\n",
    "\n",
    "## Requirements\n",
    "- OpenAI Python package\n",
    "- [OpenAI API key](https://platform.openai.com/docs/guides/authentication)\n",
    "\n",
    "## [Optional] Use a virtual environment\n",
    "It is recommended to use a virtual environment to manage the dependencies of your project. You can create a virtual environment using `venv` or `conda`. Here is an example using `conda`:\n",
    "```bash\n",
    "# Create a new virtual environment\n",
    "conda create -n openai python=3.10\n",
    "\n",
    "# Activate the virtual environment\n",
    "conda activate openai\n",
    "\n",
    "# Install the required packages\n",
    "pip install openai\n",
    "```\n",
    "\n",
    "Otherwise, you can install the required packages globally using `pip`:\n",
    "```bash\n",
    "pip install openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "\n",
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The API key is required to access the OpenAI API\n",
    "# You can get the API key from the OpenAI dashboard\n",
    "# Remember to keep your API key secret!\n",
    "API_KEY = None\n",
    "\n",
    "# If the API key is not defined, then we will try to get it from the environment variables\n",
    "if not API_KEY:\n",
    "    API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# If the API key is still not defined, then we will raise an exception\n",
    "if not API_KEY:\n",
    "    raise Exception(\"API Key is not defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to use for the translation\n",
    "SYSTEM_NAME = \"gpt-4o-mini-2024-07-18\"\n",
    "\n",
    "# If you want to use a more powerful (and more expensive) model, then you can use the following model\n",
    "# SYSTEM_NAME = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "# Source language (language to translate from); default is English\n",
    "SOURCE_LANGUAGE = \"English\"\n",
    "\n",
    "# Target language (language to translate to); default is all languages\n",
    "TARGET_LANGUAGES = [\n",
    "    \"Arabic\",\n",
    "    \"Chinese (Traditional)\",\n",
    "    \"French\",\n",
    "    \"German\",\n",
    "    \"Italian\",\n",
    "    \"Japanese\",\n",
    "    \"Korean\",\n",
    "    \"Spanish\",\n",
    "    \"Thai\",\n",
    "    \"Turkish\",\n",
    "]\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = \"../data\"\n",
    "SPLIT = \"validation\"\n",
    "\n",
    "# Mapping language to language code\n",
    "LANGUAGES = {\n",
    "    \"Arabic\": \"ar_AE\",\n",
    "    \"English\": \"en_US\",\n",
    "    \"French\": \"fr_FR\",\n",
    "    \"German\": \"de_DE\",\n",
    "    \"Italian\": \"it_IT\",\n",
    "    \"Japanese\": \"ja_JP\",\n",
    "    \"Korean\": \"ko_KR\",\n",
    "    \"Thai\": \"th_TH\",\n",
    "    \"Turkish\": \"tr_TR\",\n",
    "    \"Spanish\": \"es_ES\",\n",
    "    \"Chinese (Traditional)\": \"zh_TW\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_references(path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load the text to translate from the given path.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the file containing the text to translate.\n",
    "\n",
    "    Returns:\n",
    "        references (dict): A dictionary containing the text to translate.\n",
    "    \"\"\"\n",
    "    references = {}\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            references[data[\"id\"]] = data\n",
    "\n",
    "    print(f\"Loaded {len(references)} references from {path}\")\n",
    "    return references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(predictions, path):\n",
    "    \"\"\"\n",
    "    Save the predictions to the given path.\n",
    "\n",
    "    Args:\n",
    "        predictions (dict): The predictions to save.\n",
    "        path (str): The path to save the predictions.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    with open(path, \"w\") as f:\n",
    "\n",
    "        for prediction in predictions.values():\n",
    "            f.write(json.dumps(prediction, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(\n",
    "    client: OpenAI,\n",
    "    text: str,\n",
    "    source_language: str,\n",
    "    target_language: str,\n",
    "    max_retries: int = 3,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Translate the given text from the source language to the target language.\n",
    "\n",
    "    Args:\n",
    "        client (OpenAI): The OpenAI client.\n",
    "        text (str): The text to translate.\n",
    "        source_language (str): The source language.\n",
    "        target_language (str): The target language.\n",
    "        max_retries (int): The maximum number of retries.\n",
    "\n",
    "    Returns:\n",
    "        translation (str): The translated text.\n",
    "    \"\"\"\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=SYSTEM_NAME,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": f\"You are an expert translator. Translate from {source_language} to {target_language}. Only provide the translation without explanations.\",\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": text},\n",
    "                ],\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            if retries == max_retries:\n",
    "                print(f\"Failed to translate text after {max_retries} attempts: {e}\")\n",
    "                return None\n",
    "            print(f\"Attempt {retries} failed: {e}. Retrying...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating to Arabic...\n",
      "Loaded 722 references from ../data/references/validation/ar_AE.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 722/722 [07:29<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 722 predictions to ../data/predictions/gpt-4o-2024-08-06/validation/ar_AE.jsonl\n",
      "Translating to Chinese (Traditional)...\n",
      "Loaded 722 references from ../data/references/validation/zh_TW.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 722/722 [07:50<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 722 predictions to ../data/predictions/gpt-4o-2024-08-06/validation/zh_TW.jsonl\n",
      "Translating to French...\n",
      "Loaded 724 references from ../data/references/validation/fr_FR.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 724/724 [07:24<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 724 predictions to ../data/predictions/gpt-4o-2024-08-06/validation/fr_FR.jsonl\n",
      "Translating to German...\n",
      "Loaded 731 references from ../data/references/validation/de_DE.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 731/731 [07:51<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 731 predictions to ../data/predictions/gpt-4o-2024-08-06/validation/de_DE.jsonl\n",
      "Translating to Italian...\n",
      "Loaded 730 references from ../data/references/validation/it_IT.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 730/730 [07:41<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 730 predictions to ../data/predictions/gpt-4o-2024-08-06/validation/it_IT.jsonl\n",
      "Translating to Japanese...\n",
      "Loaded 723 references from ../data/references/validation/ja_JP.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 723/723 [08:28<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 723 predictions to ../data/predictions/gpt-4o-2024-08-06/validation/ja_JP.jsonl\n",
      "Translating to Korean...\n",
      "Loaded 745 references from ../data/references/validation/ko_KR.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 745/745 [08:28<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 745 predictions to ../data/predictions/gpt-4o-2024-08-06/validation/ko_KR.jsonl\n",
      "Translating to Spanish...\n",
      "Loaded 739 references from ../data/references/validation/es_ES.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 739/739 [08:13<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 739 predictions to ../data/predictions/gpt-4o-2024-08-06/validation/es_ES.jsonl\n",
      "Translating to Thai...\n",
      "Loaded 710 references from ../data/references/validation/th_TH.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 710/710 [15:08<00:00,  1.28s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 710 predictions to ../data/predictions/gpt-4o-2024-08-06/validation/th_TH.jsonl\n",
      "Translating to Turkish...\n",
      "Loaded 732 references from ../data/references/validation/tr_TR.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 732/732 [07:57<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 732 predictions to ../data/predictions/gpt-4o-2024-08-06/validation/tr_TR.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Translate the text to each target language\n",
    "for target_language in TARGET_LANGUAGES:\n",
    "    print(f\"Translating to {target_language}...\")\n",
    "\n",
    "    # The path to the references is formatted as follows:\n",
    "    # data/references/{split}/{target_language}.jsonl\n",
    "    path_to_references = os.path.join(\n",
    "        DATA_DIR,\n",
    "        \"references\",\n",
    "        SPLIT,\n",
    "        f\"{LANGUAGES[target_language]}.jsonl\",\n",
    "    )\n",
    "\n",
    "    # The path to the predictions is formatted as follows:\n",
    "    # data/predictions/{system_name}/{split}/{target_language}.jsonl\n",
    "    path_to_predictions = os.path.join(\n",
    "        DATA_DIR,\n",
    "        \"predictions\",\n",
    "        SYSTEM_NAME,\n",
    "        SPLIT,\n",
    "        f\"{LANGUAGES[target_language]}.jsonl\",\n",
    "    )\n",
    "\n",
    "    # Load the references\n",
    "    references = load_references(path_to_references)\n",
    "\n",
    "    # Translate the text\n",
    "    predictions = {}\n",
    "\n",
    "    for id, reference in tqdm.tqdm(references.items()):\n",
    "        source_text = reference[\"source\"]\n",
    "        prediction = translate_text(\n",
    "            client, source_text, SOURCE_LANGUAGE, target_language\n",
    "        )\n",
    "\n",
    "        if prediction is None:\n",
    "            print(f\"Failed to translate text for id {id}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        predictions[id] = {\n",
    "            \"id\": id,\n",
    "            \"source_language\": SOURCE_LANGUAGE,\n",
    "            \"target_language\": target_language,\n",
    "            \"text\": source_text,\n",
    "            \"prediction\": prediction,\n",
    "        }\n",
    "\n",
    "    # Save the predictions\n",
    "    save_predictions(predictions, path_to_predictions)\n",
    "    print(f\"Saved {len(predictions)} predictions to {path_to_predictions}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ea-mt-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
